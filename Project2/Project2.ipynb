{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 2 - Genetic Algorithm for Image Reconstruction.**\n",
    "**Subject:** MC906/MO416 - Introduction to Artificial Intelligence \n",
    "\n",
    "**Authors:**\n",
    "\n",
    "    Eduardo Barros Innarelli - RA 170161\n",
    "    Victor Ferreira Ferrari  - RA 187890\n",
    "    Vinicius Couto Espindola - RA 188115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**\n",
    "### Project\n",
    "The project consists of a study of genetic algorithm-based solutions for **image reconstruction**. A few set aspects of the problem will be explained, implemented and discussed here, such as:\n",
    "\n",
    "- The **modeling** of the problem as an evolutionary problem (chromosomes, genes, etc);\n",
    "- How to **generate the initial population**;\n",
    "- The chosen **fitness function**;\n",
    "- How to **visualize** the result.\n",
    "\n",
    "Along with that, some aspects of the genetic algorithm will be tested and discussed with multiple approaches, such as:\n",
    "\n",
    "- Stop criteria;\n",
    "- Selection technique;\n",
    "- Crossover technique;\n",
    "- Mutation technique;\n",
    "- Generation replacement method.\n",
    "\n",
    "Also, the following **parameters** will be tested with multiple values as well:\n",
    "- Population size;\n",
    "- Mutation rate;\n",
    "- Crossover rate.\n",
    "\n",
    "In the end, different variations of the process will be compared and discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "\n",
    "This project uses the external libraries _OpenCV_ for image reading and manipulation, _NumPy_ for array manipulation, _MatPlotLib_ for result visualization and _Pandas_ for better tables/data organization. The other imports are part of the Standard Python Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import gridspec, cm\n",
    "from cv2 import imread, imwrite, resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Python Libraries\n",
    "import glob\n",
    "from time import time\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "from random import sample, choices, shuffle\n",
    "from os.path import join, basename\n",
    "\n",
    "# IPython Libraries\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem**\n",
    "### General Information\n",
    "The problem consists of, given the original image, recreating an image from scratch. The original is only used for fitness purposes (how good is the image generated). This is not particularly useful in many applications, but can be used as basis for other problems, and is good for the purpose of this project: test different methods of reproduction, mutation, etc.\n",
    "\n",
    "The motivation came from [Roger Johansson's \"Evolution of Mona Lisa\"](https://rogerjohansson.blog/2008/12/07/genetic-programming-evolution-of-mona-lisa/), but instead of using polygons, the pixel values are directly used.\n",
    "\n",
    "### Modeling\n",
    "The modeling of the problem as a GA problem is almost direct: the image is the individual (chromosome) and each of its pixels is a gene. The image can be represented by a multitude of different ways. The chosen way of representation is as a flat array, as this allows for easier operations, especially crossover.\n",
    "\n",
    "### Inputs\n",
    "Due to the huge number of combinations in a regular RGB image ($255^3$ possiblities per pixel), greyscale images are used in this project. High resolution images were rescaled to a lower resolution using *OpenCV* as some images would simply take too long to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on Structure\n",
    "\n",
    "The code was organized in such a manner which allows us to first define every method used as well as discuss them in separated modules, making each part more readable and comprehesible.\n",
    "\n",
    "In order to merge all components of the code, we created a class called GeneticAlgorithm. This class retains some essential variables for the methods defined along the report. To allow such methods to access these variables (even though they are not a part of the class) nearly every method must receive as it's **first parameter the class instance** which is referred as the **parameter 'self' in the method's definitions**. It should also be noted that the method usualy have no return statements, simply because the 'self' parameter is a reference to the class instance, which **allow the methods to make changes in-place**.\n",
    "\n",
    "To specify which class variables are necessary/used and which are defined/altered by the methods in each section, there will be a list of **used class variables** and **defined class variables** within the description of every section. On top of these uses and definitions, there are parameters which are method dependent, these are in the sections **necessary parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Goal Image\n",
    "\n",
    "Before starting the algorithm we must first read an image from memory. To do so we'll use the read function embedded in the GeneticAlgorithm class. This function is responsible for reading the image, reducing it's resolution, flattening it to an array and finally storing it in the class.\n",
    "\n",
    "The read image is kept in two class variables: \n",
    " 1. *self.goal* - The flattened image, which is an array containing the input image pixels. \n",
    " 2. *self.shape* - After dowscalling and before flattening the image, we must save the input image shape so we can reverse the flattening process allowing us to visualize the array of genes as an image.\n",
    " \n",
    "**Note:** a relevant detais is that the length of the array kept in *self.goal* is the amount of genes every individual must have, so we'll often use the variable *self.goal.size* to set the amount of genes in methods were this information is necessary.\n",
    "\n",
    "Since processing the input image is the first step of the algorithm, the methods defined bellow this section will consider that the class variables *self.goal* and *self.shape* are defined and ready to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Initialization\n",
    "**Responsible: Vinícius and Victor**\n",
    "\n",
    "The first step to run a genetic algorithm is creating a population to serve as a starting point for the selection, reproduction and mutation process. \n",
    "\n",
    "**Necessary parameters:**\n",
    " 1. *pop_size* - Defines the amount of individuals to be created in the initial population.\n",
    "\n",
    "**Used class variables:** \n",
    " 1. *self.goal.size* - Defines the amount of genes that every individual must have.\n",
    "\n",
    "**Defined class variables:**\n",
    " 1. *self.population* - List of *ndarrays* where each element contains the genes of an individual.\n",
    " 2. *self.all_fits* - List of float values where each element is the fitness of an individual.\n",
    " 3. *self.pop_size* - Saves the value chosen for population size (*pop_size* parameter).\n",
    "\n",
    "The following code defines some methods which will be used to create a population out of nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Initialization\n",
    "The first method chosen for this stage was the completely random initialization. Here we simply randomize every gene of the *pop_size* individuals considering the possible state space, in other words, we generate *pop_size* arrays by randomizing every of it's *self.goal.size* elements within the range $[0-255]$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random(self, pop_size):\n",
    "    # Generate completely random indivuduals \n",
    "    self.population = []\n",
    "    size = self.goal.size\n",
    "    \n",
    "    for i in range(pop_size):\n",
    "        print(f\"Generating Population...  {i:>3}/{pop_size}\\r\", end='')\n",
    "        person = np.random.randint(0, 256, size, dtype=np.uint8)\n",
    "        self.population.append(person)\n",
    "    self.pop_size = pop_size\n",
    "    print(f\"{' '*50}\\r\", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partially Random Initialization\n",
    "\n",
    "The complete random initilization isn't very helpful to provide a good starting point for the algorithm, allowing the initial population to be completely unfit when compared to the goal image. An alternative would be to insert one completely white individual with the others. This way, depending on the goal image, this individual can start better fit than the others.\n",
    "\n",
    "This method does not ensure a better starting point for all images, though. For some images, as can be seen in the \"Result\" section, this white individual can make the entire population have a white section, over time. If, in the goal image, this section is not white, the algorithm depends on mutation to insert different values in that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_and_random(self, pop_size):\n",
    "    self.population = []\n",
    "    size = self.goal.size\n",
    "    \n",
    "    person = np.full(size, 255, dtype=np.uint8)\n",
    "    self.population.append(person)\n",
    "    \n",
    "    for i in range(pop_size-1):\n",
    "        print(f\"Generating Population...  {i+1:>3}/{pop_size}\\r\", end='')\n",
    "        person = np.random.randint(0, 256, size, dtype=np.uint8)\n",
    "        self.population.append(person)\n",
    "    self.pop_size = pop_size\n",
    "    print(f\"{' '*50}\\r\", end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function\n",
    "**Responsible: Victor**\n",
    "\n",
    "For each individual, we must determine a method which will tell us how apt such individual for the problem in question.\n",
    "\n",
    "The MSE (mean squared error) is a very common error function for AI and Machine Learning models, so that was implemented here. Since we want more distance between the individuals when the error is low enough, we can use the squared error directly, without taking the mean. This makes for a big number, and more distance between individuals.\n",
    "\n",
    "Finally, a \"correct pixels\" fitness function was made, to identify how many pixels are exactly the same as the goal image. This can be useful because it doesn't allow for much approximation, relying on directly imitating the goal image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_error(individual, original):\n",
    "     return ((original.astype(np.float64) - individual.astype(np.float64))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(individual, original):\n",
    "     return squared_error(individual,original)/individual.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pixels(individual, original):\n",
    "    return np.count_nonzero(original.astype(np.int16) - individual.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence Criteria\n",
    "**Responsible: Vinícius**\n",
    "\n",
    "The algorithm cannot run forever. In this section will define a convergence method for halting the program's exection. \n",
    "\n",
    "The convergence function must identify when the algorithm's improvement rate has significantly decreased or even stalled. To do so, it must know to some extent the rate of improvement per generation, which can be infered by the difficulty of improving the best individual found so far. Assume we have the best indivudual so far ($B$), therefore, we can estimate when the algorithm is decreasing it's evolution rate (or improvement rate) by checking how many generations have passed since $B$ was achieved: the more generations where $B$ wasn't improved, the more likely is that the algorithm has converged. The convergence method defined in this section is based on this idea.\n",
    "\n",
    "The convergence method will also play a secondary role: it is responsible for updating the best individual found across all generations, such individual is used as the final generated image which will be compared with the goal image.\n",
    "\n",
    "**Necessary parameters:**\n",
    " 1. *limit* - Suppose generation $X$ has the best individual so far, also suppose we are at generation $Y|Y>X$. This implies that the last $L=Y-X$ generation(s) did not improve the fittest individual found so far. If $L>limit$ we consider that the algorithm has converged.\n",
    "\n",
    "**Used class variables:** \n",
    " 1. *self.all_fits* - Used to find the fittest individual of the new generation by getting the minimum fitness.\n",
    " 2. *self.best_fit* - Holds the fittness of the best individual across all previous generations.\n",
    "\n",
    "**Defined class variables:**\n",
    " 1. *self.counter* - Counts generations since the last improvement of the best individual.\n",
    " 2. *self.best_genfit* - If theres a new better individual we must update this variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convergence Halting Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convergence(self, limit):\n",
    "    ''' Identifies convergence and updates fittest individual found so far \n",
    "        \n",
    "        Parameters:\n",
    "            self - GeneticAlgorithm class which the function is being called from\n",
    "            limit - Amount of iterations wich can be worst than the best one found so far\n",
    "        Return:\n",
    "            Bool - True if converged, False otherwise.\n",
    "    '''\n",
    "    # Get min fitness for population\n",
    "    new_genfit = self.all_fits.min()\n",
    "     \n",
    "    # Update number of iterations without improvement\n",
    "    if new_genfit >= self.best_genfit:\n",
    "        self.counter += 1\n",
    "    else:\n",
    "        self.counter = 0\n",
    "        self.best_genfit = new_genfit\n",
    "    \n",
    "    # Check convergence\n",
    "    if self.counter >= limit or self.best_genfit <= 0:\n",
    "        self.counter = 0\n",
    "        return True\n",
    "    else:\n",
    "        return False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secondary Halting Method \n",
    "\n",
    "Even checking for convergence, the algorithm might still present sufficiently small improvements to avoid convergence, however, they might be so small that it will take a enormous amount of time to converge. As a failsafe to this scenario, we will limit the total amount of generations that can be created. This secondary halting method is not defined in this section however, it is defined withing the GeneticAlgorithm class as *self.abort()*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parents Selection\n",
    "**Responsible: Vinícius and Victor**\n",
    "\n",
    "In this section we'll define methods responsible for selecting from the population individuals responsible for bearing the next generation. The main goal is to find a method which properly balances the diversity and quality of the new generation of individuals.\n",
    "\n",
    "An analysis of the fitness values showed that the individuals tend to have similar fit in the model we created, leading to premature convergence. This can affect methods such as *roulette selection* which depend heavily on the difference between the fitness score of individuals. A possible solution to this was to apply exponential transfer on the fitness values of the individuals so one does not monopolize the probability, which could lead to homogenization. Another solution to prevent this issue was to implement methods which depend on the comparison among a group of individuals chosen with equal probability. An example of such method is the *tournament selection*.  \n",
    "\n",
    "**Necessary parameters:**\n",
    " 1. *N* - The amount of individuals which will be selected for reproduction.\n",
    " 2. *k* - Defines the amount of competiors in each tournament (tournament selection only).\n",
    " 3. *P* - Defines how many partners an individual can have (tournament selecion only).\n",
    " 4. *T* - Defines the maximum amount of couples allowed (tournament selection only).\n",
    " \n",
    "**Used class variables:** \n",
    " 1. *self.pop_size:* Used to define the range of the individuals indexes within the population.\n",
    " 2. *self.all_fits:* The selection is based on the individuals fitness, therefore this variable is accessed.\n",
    " \n",
    "**Defined class variables:**\n",
    " 1. *self.mates:* creates a list of tuples where each tuple pairs the index of two individuals for reproduction.\n",
    " \n",
    "The following code defines some methods which will be used to select individual for the creation of the next generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tournament Selection\n",
    "\n",
    "Suppose we're given a population $P$. The tournament method will randomly select $k$ individuals out of $P$, then the fittest individual out of the $K$ selected will be chosen to partake in the reproduction step. This process is repeated until we have selected $N$ winners.\n",
    "The second step is pairing the $N$ winners among themselves creating couples. This step is done by first creating every two number combination possible with the $N$ elements and then applying restrictions over which pairs from the combination will be a valid couple. \n",
    "\n",
    "Suppose we have an element $x\\in N$:\n",
    " 1. *$x$ will never form a couple with itself* - A child of the couple $(x,x)$ would simply produce $x$.\n",
    " 2. *$x$ will only match with some $y \\in N$ exactly once* - Repeating couples such as $(x,y)$ and $(y,x)$ is likely to reduce the population's diversity.\n",
    " 3. *$x$ can be in at most $P$ of the selected couples* - If an element $x$ partakes in multiple couples, diversity is likely to deteriorate.\n",
    "\n",
    "The couples will be matched using elements from $N$ and obeying the previous restrictions, we can pick at most $T$ pairs.\n",
    "\n",
    "In this method the size of $K$ controls diversity: when $K$ is larger, it's more likely that unfit individuals are competing with fitter ones, therefore there will likely be a smaller diversity within the population. If we seek more diversity, a smaller $k$ might help. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament(self, k, N, P, T):\n",
    "    pool = list(range(self.pop_size))\n",
    "    pairs = {x:set() for x in pool}\n",
    "    fitness = lambda x: self.all_fits[x]\n",
    "    winners,self.mates = [],[]\n",
    "\n",
    "    # Run tournament to pick N winners\n",
    "    while len(winners) < N:\n",
    "        competitors = np.random.choice(pool, size=k, replace=False)\n",
    "        winner = min(competitors, key=fitness)\n",
    "        winners.append(winner)\n",
    "        pool.remove(winner) # remove winner from pool\n",
    "    \n",
    "    # Combination: given a pool of winners, match them as couples\n",
    "    shuffle(winners)\n",
    "    for (dad,mom) in combinations(winners, 2):\n",
    "        if (len(pairs[dad]) < P) and (len(pairs[mom]) < P): \n",
    "            pairs[dad].add(mom)\n",
    "            pairs[mom].add(dad)\n",
    "            self.mates.append((dad,mom))\n",
    "            if len(self.mates) == T: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Roulette Method\n",
    "\n",
    "Suppose we're given a population $P$. The roulette method will attribute a probability for each individual according to it's fitness value: lower fits implies high probability and higher fits implies lower probabilities. This allows a stochastic method to prize the quality individual without losing too much diversity, especially since _exponential transfer_ is used as a method to avoid premature convergence.\n",
    "\n",
    "In contrast with the tournament method, the roulette does not discriminate individuals. For that reason, any individual can be matched with any other individual, including with itself, and the same match can happen multiple times. That is why a way to avoid premature convergence is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette(self, N):\n",
    "    fit = self.all_fits\n",
    "    size = self.pop_size\n",
    "    \n",
    "    # Exponential transfer.\n",
    "    fit = np.sqrt(fit+1)\n",
    "    \n",
    "    # Roulette method: select N individuals from the population,\n",
    "    # with proportional probabilities to their fitness values.\n",
    "    probs = fit/fit.sum()\n",
    "    probs = (1-probs)/(size-1)\n",
    "    winners = np.random.choice(np.arange(size), size=N, replace=True, p=probs)    \n",
    "    \n",
    "    self.mates = list(zip(winners[::2],winners[1::2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover Techniques\n",
    "**Responsible: Eduardo and Victor**\n",
    "\n",
    "In this section we'll define methods that generate descendants from selected parents. \n",
    "\n",
    "Based on genetic recombination, crossover exchanges genes between two individuals in a stochastic manner, resulting in a new one. Computationally, the way genes are swapped depends on the method implemented. By reproducting, the population preserves genetic diversity between generations.\n",
    "\n",
    "**Necessary parameters:**\n",
    " 1. *K* - Determines the ammount of points to use when applying k-point crossover.\n",
    " 2. *Window* - Tuple with the size of the window for the crossover (block crossover only).\n",
    " \n",
    "**Used class variables:** \n",
    " 1. *self.goal.size* - This attribute tells us how many genes are there in a individual.\n",
    " 1. *self.mates* - Each couple in this variable will be parents in the reproduction method.\n",
    " \n",
    "**Defined class variables:**\n",
    " 1. *self.children* - These are the new individuals generated from reproduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Point Crossover Reproduction\n",
    "\n",
    "Supose we're given two individuals $A$ and $B$. This method will split the individual genes in $K$ points and exchagen the resulting sections of genes. The algorithm is quite simple: get the amount of genes $G$, select $K$ points within the range $[0-G]$ then swap the genes among parents within the ranges define by the range and the $K$ points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_point_crossover(self, k):\n",
    "    ''' \n",
    "    For each couple, K points are picked randomly from their chromossomes and\n",
    "    genes between these points are swapped, intercalating pairs of points.\n",
    "    \n",
    "    Parameters:\n",
    "        self - GeneticAlgorithm class which the function is being called from\n",
    "        k - Amount of crossover points for gene exchange\n",
    "    '''\n",
    "    \n",
    "    num_genes = self.goal.size\n",
    "    self.children = []\n",
    "\n",
    "    for father, mother in self.mates:\n",
    "        # Save k unique random crosspoints in a sorted list\n",
    "        crosspoints = sorted(sample(range(0, num_genes-1), k))\n",
    "        \n",
    "        # Deep copy to freely change values\n",
    "        father = self.population[father].copy()\n",
    "        mother = self.population[mother].copy()\n",
    "        \n",
    "        # List of crosspoint pairs, adding a pair with last crosspoint\n",
    "        # and last pixel\n",
    "        # Ex: \n",
    "        # 16 pixels, points [1,9,12] -> pairs [(1,9), (9,12), (12,16)]\n",
    "        pairs = list(zip(crosspoints,crosspoints[1:]))\n",
    "        pairs.append(tuple((crosspoints[-1], num_genes)))\n",
    "\n",
    "        # Perform crossover in pair range, intercalating pairs\n",
    "        for start, end in pairs[::2]:\n",
    "            father[start:end], mother[start:end] = mother[start:end], father[start:end]\n",
    "        \n",
    "        self.children += [father, mother]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block Crossover Reproduction\n",
    "\n",
    "As mentioned previously, the individuals are represented by a flattened version, in an 1D array. However, it is still an image, and the best representation is as a 2D array, because a pixel usually is related to the one above or below, and not only the ones in the same row.\n",
    "\n",
    "For that reason, crossover by blocks or windows, instead of rows, can be more effective in minimizing fitness. The following method crosses over random windows of fixed sizes between pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_crossover(self, window):\n",
    "    self.children = []\n",
    "    \n",
    "    for father, mother in self.mates:\n",
    "        father = self.population[father].copy()\n",
    "        father.reshape(self.shape)\n",
    "        mother = self.population[mother].copy()\n",
    "        mother.reshape(self.shape)\n",
    "        \n",
    "        start_lin = np.random.randint(0, self.shape[0]-window[0])\n",
    "        start_col = np.random.randint(0, self.shape[1]-window[1])\n",
    "        \n",
    "        idx = []\n",
    "        for i in range(window[0]):\n",
    "            fun = lambda x: (start_lin+i, start_col+x)\n",
    "            idx += [fun(x) for x in range(window[1])]\n",
    "\n",
    "        father[idx],mother[idx] = mother[idx],father[idx]\n",
    "        self.children += [father.ravel(), mother.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutation Method\n",
    "**Responsible: Victor**\n",
    "\n",
    "Just permuting the genes of the previous generation might reduce the diversity among individuals by creating childs which are too similar to their parents. To counter this we'll use mutation methods allowing genes to mix within individuals.\n",
    "\n",
    "The core idea of mutation methods are to affect some genes of some individuals with some unpredictable alteration. This granular insertion of randomness can revive diversity in a homogeneous population without causing the quality of individuals to deteriorate (which would conflict with the selection and reproduction steps). There are two core values to ensure the granularity of these changes: the *Mutation Rate* defines a percentage of individuals which will mutate, and the *Mutation Amount* defines the percentage of genes which will mutate per individual.\n",
    "\n",
    "**Necessary parameters:**\n",
    " 1. *MR* - Mutation rate dictates the probability of an individual to mutate.\n",
    " 2. *MA* - Mutation amount defines the amount of genes which will mutate.\n",
    " \n",
    "**Used class variables:** \n",
    " 1. *self.goal.size* - This attribute tells us how many genes are there in a individual.\n",
    " 1. *self.children* - Mutations are applied only on the individuals resulting from the reproduction step.\n",
    " \n",
    "**Defined class variables:**\n",
    " 1. *self.children* - The childrens gene are altered in-place altering this value.\n",
    "\n",
    "The following code defines some methods which will be used to mutate the individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Mutation\n",
    "\n",
    "Given a population $P$ where each individual has $G$ genes, randomly pick $MR\\cdot |P|$ individuals and for each of these individuals randomly pick $M\\cdot |G|$ genes to ramdomize within the range $[0-255]$. Quite straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mut(self, MR, MA):\n",
    "    # Set some synonyms\n",
    "    size = self.goal.size\n",
    "    pop  = self.children\n",
    "    \n",
    "    # Select individuals to mutate.\n",
    "    mut_amount = int(MR*len(pop)) # amount of individuals to mutate\n",
    "    individuals = choices(pop, k=mut_amount)\n",
    "    \n",
    "    # Change elements to random value.\n",
    "    gene_amount = int(MA*size) # amount of genes to mutate per individual\n",
    "    for i in individuals:\n",
    "        genes = np.random.choice(size, gene_amount, replace=False)\n",
    "        new   = np.random.randint(0, 256, gene_amount, np.uint8)\n",
    "        i[genes] = new # Changes are in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced Mutation\n",
    "\n",
    "This method is quite similar to the previous, still picking the same amount of individuals and genes randomly, but this time exploring a property of images. Small variations on pixels are visible, but a somewhat different shade can still result in a similar image. Therefore, we can restrict the amount of shades the mutated genes can receive, in the interest of getting a \"good enough\" approximation instead of the same exact image as the goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_mut(self, MR, MA):\n",
    "    # Set some synonyms\n",
    "    size = self.goal.size\n",
    "    pop  = self.children\n",
    "    \n",
    "    # Select individuals to mutate.\n",
    "    mut_amount = int(MR*len(pop)) # amount of individuals to mutate\n",
    "    individuals = choices(pop, k=mut_amount)\n",
    "    \n",
    "    # Change elements to random value.\n",
    "    gene_amount = int(MA*size) # amount of genes to mutate per individual\n",
    "    for i in individuals:\n",
    "        genes = np.random.choice(size, gene_amount, replace=False)\n",
    "        new   = np.random.randint(0, 32, gene_amount, np.uint8)\n",
    "        i[genes] = new*8 # Changes are in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Increment Mutation\n",
    "\n",
    "We'll repeat most of the steps from the previous method, however we'll also constraint how much each gene can mutate based on the original value of the gene. Suppose we will mutate some gene $g$, when doing so this mutation will be constrained to be within some range $[g-\\epsilon,g+\\epsilon]$. The main goal of this method is to have a even more fine control of the mutation. In this case, $\\epsilon$ is not a parameter, but a constant $\\epsilon=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_mut(self, MR, MA):\n",
    "    # Set some synonyms\n",
    "    size = self.goal.size\n",
    "    pop  = self.children\n",
    "    \n",
    "    # Select individuals to mutate.\n",
    "    mut_amount = int(MR*len(pop)) # amount of individuals to mutate\n",
    "    individuals = choices(pop, k=mut_amount)\n",
    "    \n",
    "    # Change elements to random value.\n",
    "    gene_amount = int(MA*size) # amount of genes to mutate per individual\n",
    "    for i in individuals:\n",
    "        genes = np.random.choice(size, gene_amount, replace=False)\n",
    "        new   = np.random.randint(-10, 11, gene_amount, np.int8)\n",
    "        i[genes] += new # Changes are in-place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacement Techniques\n",
    "**Responsible: Eduardo**\n",
    "\n",
    "In this stage we're storing both the parents and their children. Increasing the population size can affect the algorithm performance in terms of memory usage and time as well as the convergence rate due to unfit individuals being kept alive. To mitigate this, it's necessary to choose which individuals will remain in the new generation.\n",
    "\n",
    "**Necessary parameters:**\n",
    " - None.\n",
    " \n",
    "**Used class variables:** \n",
    " 1. *self.children* - Calculates the fitness of every child to apply the replacement method.\n",
    " \n",
    "**Defined class variables:**\n",
    " 1. *self.all_fits* - Will be updated with the fitness of the individuals that survived the replacement.\n",
    " 2. *self.population* - The population will also be updated with the individuals that survived the replacement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elitism\n",
    "\n",
    "The elitism replacement method follows the \"survival of the fittest\" principle, where the children are placed in the same pool as the previous generation, and the $N$ best individuals from that pool are chosen to survive. This speeds up convergence, since the population is always improving before converging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elitism(self):\n",
    "    ''' \n",
    "    Preserve the fittest individuals between both parents and children\n",
    "        \n",
    "    Parameters:\n",
    "        self - GeneticAlgorithm class which the function is being called from\n",
    "    '''\n",
    "    \n",
    "    # Calculate children fitness.\n",
    "    generator = map(lambda x: self.fit(x, self.goal), self.children)\n",
    "    all_fits = np.concatenate((self.all_fits, np.array(list(generator), dtype=np.float64)))\n",
    "    \n",
    "    # Sort fits and population by fits.\n",
    "    idxs = all_fits.argsort()\n",
    "    full = self.population + self.children\n",
    "    full = np.array(full)\n",
    "    \n",
    "    # Combine parents with children, sorted by fitness function\n",
    "    combined = full[idxs]\n",
    "    all_fits = all_fits[idxs]\n",
    "    \n",
    "    # Update population with the fittest individuals\n",
    "    self.population = list(combined[:self.pop_size])\n",
    "    self.all_fits = all_fits[:self.pop_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steady State\n",
    "\n",
    "The steady state replacement method ensures that all children generated in this generation are included in the next one. This means that, if $N$ children are created, this has the same effect as a generational replacement. If $M<N$, though, those $M$ children will replace the **least fit** parents.\n",
    "\n",
    "This method is interesting because it gives incentive to diversity, since all children are included in the next generation, while still preserving the best from the previous generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steady_state(self):\n",
    "    ''' \n",
    "    Children replaces the least fit parents.\n",
    "    \n",
    "    Obs: if number of children and parents are equal, this has the same\n",
    "    effect as a generational replacement.\n",
    "    \n",
    "    Parameters:\n",
    "        self - GeneticAlgorithm class which the function is being called from\n",
    "    '''\n",
    "    \n",
    "    pop_sorted = sorted(range(self.pop_size), key = lambda x: self.all_fits[x])\n",
    "    \n",
    "    # Replace worst fits from population with childs\n",
    "    while self.children and pop_sorted:\n",
    "        old = pop_sorted.pop()\n",
    "        new = self.children.pop()\n",
    "        self.population[old] = new\n",
    "        self.all_fits[old] = self.fit(new, self.goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Genetic Algorithm Class**\n",
    "**Responsible: Vinícius and Victor**\n",
    "\n",
    "The class will be responsible for selecting which methods will be used for the genetic algorithms steps as well as define it's parameters and executing the main loop. The main loop will be responsible for properly calling the methods and computing any in between tasks, as well as checking for halting conditions and picking the fittest individual found in all generations. This pattern was chosen as a way facilitate testing with different methods and parameters as well making the report modular.\n",
    "\n",
    "##### Initialization Process\n",
    "\n",
    "The initialization must receive the methods for each step (initialization, selection, reproduction, mutation and replacement), the fitness function to be used and the maximum amount of generations to be created. It's also responsible for defining the class variables which are shared among methods.\n",
    "\n",
    "The functions used for each step of the algorithm have the following declaration: `f(self, x, y, ...)` and do not return any value. If we wish to use this function within the class we must pass both the function and it's parameters as a tuple in the initilization to the correct default arguments, which are: *limit*, *fit*, *conv*, *init*, *mating*, *crossover*, *mutate* and *replace*. \n",
    "\n",
    "Return values are not used in these methods, as all of them have access to the shared class variables in the parameter `self`, allowing changes directly to these class variables.\n",
    "\n",
    "**Examples:** Suppose function `f(self, x, y, z)` is a reproduction method, therefore we will pass the default argument `crossover` as `crossover = (f,[x,y,z])`. Suppose function `h(self)` is a replacement method, therefore we will pass the default argument `replace` as `replace = (f,None)`.\n",
    "\n",
    "This allows use to define multiple function for each step of the algorithm and select which one to use by simply changing the default argument passed in the GenericAlgorithm class initializations. We can also easily change parameters when testing.\n",
    "\n",
    "##### Fitness Update Method\n",
    "\n",
    "The `GeneticAlgorithm.update` method seeks to contain all necessary fitness update in a single function which is called only once per iteration. This is the most computationally expensive part of the algorithm, containing and calling it a single time per iteration is paramount for perfomance.\n",
    "\n",
    "##### Main Loop\n",
    "\n",
    "The `GeneticAlgorithm.test` function contains the main loop of the algorithm which is reponsible for coodinating the usage of each method defined for each step. The default parameter `graph` can be used to define datapointd for ploting the fitness values progression across generations. Whe can define `graph=list(range(100,5))` to collect data each 5 generations until we reach generation 100.\n",
    "\n",
    "##### Preprocessing and Visualization Method\n",
    "\n",
    "the `GeneticAlgorithm.read` method can read an image from a given path and downscale it accorgin to a value `res_factor`. The downscaling can be both a float value, which will alter the image resolution percentualy, or it can be a tuple of integers definig the amount of pixels in each dimension. This method also flattens the image making it into an one dimensional array, which is necessary for or model.\n",
    "\n",
    "The `GeneticAlgorithm.show` simply restored the flattened image to it's previous shape and exhibits it using _matplotlib_.\n",
    "\n",
    "##### Fitness Plotting Methods\n",
    "\n",
    "If the variable `graph` is defined when runing the main loop, the values for the worst individual in the current generation, the median individual in the current generation and the best individual found so far will be collect and exhibited in a graph at the end of the program's excution.\n",
    "\n",
    "##### Reset Method\n",
    "\n",
    "This is used only in case we want to reutilize the instance for another genetic algorithm. We can call the `GeneticAlgorithm.reset()` method and the run it again as it was the first time. This is particulary usefull if we wish to test the same instance with a single different step: suppose we want to change only the reproduction method of the instance `GA`, then we can reset `GA` and redefine the `GA.reprod` variable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    ''' The GeneticAlgorithm class retains and coordinates all necessary variables and methods\n",
    "        for the execution of the genetic algorithm created.\n",
    "        It's initialization receives the methods which will compute each step of the algorithm\n",
    "        as well as the parameters utilized by each of these methods. A limit integer is also\n",
    "        define to halt the programs execution.\n",
    "        \n",
    "        Methods:\n",
    "            run    - execute the genetic algorithm based on the instance variables/methods\n",
    "            update - recalculate individuals fitness and updates best individual so far\n",
    "            read   - read a image from file, rescale and flatten\n",
    "            show   - reshape flattened image and exhibit with matplotlib\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, \n",
    "                 limit     = 10000, # Max amount of generations to create\n",
    "                 fit       = None,  # Function to calculate individual fitness\n",
    "                 conv      = None,  # Convergence function and parameters\n",
    "                 init      = None,  # Population Initializer function and parameters\n",
    "                 mating    = None,  # Population Selection function and parameters\n",
    "                 crossover = None,  # Selected Indviduals Crossover function and parameters\n",
    "                 mutate    = None,  # Selected Indviduals Mutation function and parameters\n",
    "                 replace   = None,  # Choose which individuals are kept/replaced\n",
    "                ):\n",
    "        \n",
    "        # Halting criterias\n",
    "        self.counter = 0 # Convergence counter\n",
    "        self.limit = limit\n",
    "        self.abort = lambda: bool(self.gen_count >= self.limit)\n",
    "        \n",
    "        # Goal related variables\n",
    "        self.shape = None # Holds original downsized image shape\n",
    "        self.goal  = None # Holds an array with the ideal individual (goal image)\n",
    "        \n",
    "        # Convergence related variables\n",
    "        self.best        = None         # Best individual obtained so far\n",
    "        self.best_fit    = float('inf') # The fit score of the bets individual so far\n",
    "        self.all_fits    = None         # List of each individual fitness\n",
    "        self.best_gen    = None         # Best generation.\n",
    "        self.best_genfit = float('inf')\n",
    "        \n",
    "        # Generation related variables\n",
    "        self.pop_size   = None  # The amount of individuals kept per generation\n",
    "        self.population = None  # List of individual of the current generation\n",
    "        self.gen_count  = 1     # Current generation (first, second, ...)\n",
    "        self.mates      = None  # Paired individuals which will reproduce\n",
    "        self.children   = []\n",
    "    \n",
    "        # Static Genetic Methods Functions\n",
    "        self.fit = fit\n",
    "        self.define = lambda x: lambda: x[0](self,*x[1]) if x[1] else x[0](self)\n",
    "        self.conv      = self.define(conv)\n",
    "        self.init      = self.define(init)\n",
    "        self.mating    = self.define(mating)\n",
    "        self.crossover = self.define(crossover)\n",
    "        self.mutate    = self.define(mutate)\n",
    "        self.replace   = self.define(replace)\n",
    "        # TODO: MR needs to decrease with time to converge.\n",
    "        \n",
    "        # Auxiliar variables for analysis\n",
    "        self.time = 0\n",
    "        self.convergence_times = []\n",
    "        self.plot_points = []\n",
    "        self.plot_milestones = []\n",
    "        \n",
    "        test = [self.conv,self.init,self.mating,self.crossover,self.mutate]\n",
    "        test = all(map(bool, test))\n",
    "        assert test, \"There are undefined steps for the algorithm\"\n",
    "    \n",
    "    def test(self, img_path, res_factor=None, graph=None):\n",
    "        write_milestones = [1000, 10000, 50000, 100000, 200000, 500000, 1000000, 2000000, 3000000, 4000000, 5000000, 6000000, 7000000, 8000000, 9000000]\n",
    "        self.plot_milestones = graph\n",
    "        self.time = time()\n",
    "        self.read(img_path, res=res_factor)\n",
    "        self.init()\n",
    "        \n",
    "        generator = map(lambda x: self.fit(x, self.goal), self.population)\n",
    "        self.all_fits = np.array(list(generator), dtype=np.float64)\n",
    "        \n",
    "        while not (self.conv() or self.abort()):\n",
    "            print(f\"Current Generation: {self.gen_count:>7} (avg. fit: {self.all_fits.mean():>12.3f}). Current Best: {self.best_fit:>10} (gen {self.best_gen}).\\r\", end='')\n",
    "            \n",
    "            self.mating()     # Generate tuples indicating mating pairs\n",
    "            self.crossover()  # Generate two childs for each couple\n",
    "            self.mutate()     # Apply mutation on all individuals (old and new)\n",
    "            self.replace()    # Select which individuals will be kept\n",
    "            \n",
    "            self.gen_count += 1\n",
    "            self.update()\n",
    "            \n",
    "            if graph and self.gen_count in self.plot_milestones: \n",
    "                self.update_points()\n",
    "                self.convergence_times.append(time()-self.time)\n",
    "\n",
    "            if self.gen_count in write_milestones:\n",
    "                self.write(self.best, img_path)\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nElapsed time: {(time()-self.time):.3f}\")\n",
    "        self.counter = 0\n",
    "        self.show(self.best, compare=True, graph=graph)\n",
    "        self.write(self.best, img_path)\n",
    "    \n",
    "    def reset(self):\n",
    "        ''' Reset some variables to recycle the class with new methods and paramters'''\n",
    "        self.best        = None         # Best individual obtained so far\n",
    "        self.best_fit    = float('inf') # The fit score of the bets individual so far\n",
    "        self.best_gen    = None         # Best generation.\n",
    "        self.best_genfit = float('inf')\n",
    "        self.time        = 0\n",
    "        self.gen_count   = 0\n",
    "        self.plot_points = []\n",
    "        self.convergence_times = []\n",
    "        self.plot_milestones = []\n",
    "        return self\n",
    "        \n",
    "    def update(self):\n",
    "        ''' Updates the fitness of every individual in the population.\n",
    "            Also updates the fittest individual found among all generations.\n",
    "        '''\n",
    "        # Update fittest individual\n",
    "        idx = np.argmin(self.all_fits)\n",
    "        if self.all_fits[idx] < self.best_fit: \n",
    "            self.best     = self.population[idx].copy() # save best inividual\n",
    "            self.best_gen = self.gen_count\n",
    "            self.best_fit = self.all_fits[idx]\n",
    "\n",
    "    def update_points(self):\n",
    "        idx = sorted(range(self.pop_size), key=lambda x:self.all_fits[x])\n",
    "        best = self.best_fit\n",
    "        med = self.all_fits[idx[self.pop_size//2]]\n",
    "        worst = self.all_fits[idx[-1]]\n",
    "        self.plot_points.append((best,med,worst))\n",
    "        \n",
    "    def read(self, filepath, res=None):\n",
    "        '''Reads an image in grey scale, resizes it and extends to array.\n",
    "            Params:\n",
    "                filepath - Path to the input image to be read\n",
    "                res - Either tuple with new pixel dimensions or ratio with new scale\n",
    "            Return: \n",
    "                np.array - array with the streched image\n",
    "        '''\n",
    "        img = imread(filepath,0) # load in greyscale\n",
    "        \n",
    "        if res and tuple==type(res):\n",
    "            img = resize(img, res)\n",
    "        elif res and float==type(res):\n",
    "            w = int(img.shape[0]*res)\n",
    "            h = int(img.shape[1]*res)\n",
    "            img = resize(img, (h,w))\n",
    "            \n",
    "        self.shape = img.shape # keep shape\n",
    "        self.goal  = img.reshape(img.size)\n",
    "\n",
    "    def show(self, individual, compare=False, graph=None):\n",
    "        '''Prints the image represented by an individual.\n",
    "            Params:\n",
    "                individual - Np.array to be reshaped and printed\n",
    "        '''\n",
    "        \n",
    "        fig = plt.figure(figsize=(15,5))\n",
    "        spec = gridspec.GridSpec(ncols=3, nrows=1,\n",
    "                         width_ratios=[1, 1, 3])\n",
    "\n",
    "        # If compare mode, print goal alongside\n",
    "        if compare: \n",
    "            fig.add_subplot(spec[1])\n",
    "            goal = self.goal.copy()\n",
    "            goal = goal.reshape(self.shape)\n",
    "            plt.imshow(goal, cmap='gray')\n",
    "            plt.title('Goal')\n",
    "            plt.axis('off')\n",
    "            fig.add_subplot(spec[0])\n",
    "\n",
    "        img = individual.copy()\n",
    "        img = img.reshape(self.shape)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title('Individual')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Plot graph, if requested\n",
    "        if graph:\n",
    "            if compare: fig.add_subplot(spec[2]) # Alongside images\n",
    "            x = graph[:len(self.plot_points)]\n",
    "            y_best,y_med,y_worst = [],[],[]\n",
    "            for b,m,w in self.plot_points:\n",
    "                y_best.append(b)\n",
    "                y_med.append(m)\n",
    "                y_worst.append(w)\n",
    "            plt.plot(x, y_worst, '--', label=\"Worst\")\n",
    "            plt.plot(x, y_med, '--', label=\"Median\")\n",
    "            plt.plot(x, y_best, 'r-',label=\"Best\")\n",
    "            plt.legend()\n",
    "            plt.ylabel('Fitness')\n",
    "            plt.xlabel('Generation')\n",
    "            plt.title('Fitness per Generation')\n",
    "            \n",
    "        plt.show()\n",
    "    \n",
    "    def write(self, individual, path, folder='Outputs'):\n",
    "        img = individual.copy()\n",
    "        img = img.reshape(self.shape)\n",
    "        name= 'g' + str(self.gen_count) + '_' + basename(path)\n",
    "        imwrite(join(folder, name), img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Notes on the Implementation Process**\n",
    "\n",
    " - A method of Uniform Crossover was implemented initially, to contrast with the k-point crossover. It was extremely slow since it had to iterate through every gene (and there are a lot of genes) and randomize the possibility of gene exchange. Despite being a possible counter measure to premature convergence, it was simply to slow to use.\n",
    " - Rergarding mutation rate and mutation ammount, in our case it appeared to be better when we would use the a higher probability of mutation with a smaller number of genes to mutate. The more genes we mutate, the slower is the iteration (as we need to roll the dice more times), so a higher change of mutation was a more efficient approach agains a higher number of genes to mutate.\n",
    " - Different sizes of populations did not seem to interfere significantly with the results, as expected a smaller population converges faster but it alsos converges prematurely most times.\n",
    " - We've noted that the elitism replacement method was killing the diversity within our population. This observation was done through the average fitness of each generation: with this value we were able to note that the average fitness was always equal to the best fit so far. So there was the need to wait for a mutation to insert some diversity in the population. Changing the the replacement method was helpful to create diversity and improve the convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tests**\n",
    "**Responsible: Eduardo, Victor and Vinicius**\n",
    "\n",
    "Now that a few variations of each technique are implemented, it's possible to test multiple combinations of those methods and other parameters, and compare the final results. \n",
    "\n",
    "In this section, we'll first show which images we choosed to apply the genetic algorithm based on it's limitations and the problem nature. Then, we discuss and compare some of the methods implemented for each step of the algorithm, introducing the settings which we found that worked better as we experimented and then presenting results with other methods, justifying why they were worst in practice. With the best combination, we'll finally execute a test routine for all images, storing data for later analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Cases**\n",
    "\n",
    "As previously mentioned, the test cases are **small**, **monochromatic** images, sometimes with a reduction factor. This is due to the amount of possibilities per individual, the convergence can be very slow if the pixel count is too large. Since we are dealing with a low pixel count, pixel art and sprites are good candidates for a recognizable goal image.\n",
    "\n",
    "Along with those cases, some larger images (200x200) are also used to test scalability.\n",
    "\n",
    "All tested images are shown in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images from './images' directory\n",
    "images, img_names = [], []\n",
    "for path_name in glob.glob('images/*.png'):\n",
    "    images.append(imread(path_name, 0))\n",
    "    img_names.append(basename(path_name))\n",
    "\n",
    "# Show them in grayscale\n",
    "plt.figure(figsize=(20,10))\n",
    "columns = 7\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "    plt.title(img_names[i])\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Methods Comparison**\n",
    "####  **The Best Settings**\n",
    "\n",
    "During several experimentations, the set of methods and paramenters which appeared to be the most adequate for generating images were the ones defined in the code bellow. The instance uses the following:\n",
    "\n",
    "* Squared error as the fitness function.\n",
    "* Random population with 1 white image initilization with 75 individuals.\n",
    "* Roulette selection generating $\\frac{50}{2}$ couples.\n",
    "* 3-point crossover as the reproduction method.\n",
    "* Reduced mutation with a Mutation Rate and Amount of 5% and 2.5%, respectively.\n",
    "* Steady state as the replacement criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA = GeneticAlgorithm(\n",
    "    limit     = 100000,\n",
    "    fit       = squared_error,\n",
    "    conv      = (convergence,(10000,)), \n",
    "    init      = (white_and_random,(100,)),\n",
    "    mating    = (roulette,[50]), \n",
    "    crossover = (k_point_crossover,[3]), \n",
    "    mutate    = (reduced_mut,[0.05,0.025]), # Has a good convergence after a long time\n",
    "    replace   = (steady_state,None), \n",
    "    )\n",
    "\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple test case above can give us a glimpse of why these settings work both on the short and long run: \n",
    "* The best individual converges properly as seen in the fitness plot.\n",
    "* The worst individual has a sufficiently worst fit than the best individual indicating some diversity. \n",
    "* The oscilation in the worst individual indicate the periodic insertion of diversity within the population. \n",
    "* The median individual is nearly identical to the best individual, which indicates that the overall population fitness is also converging.\n",
    "* Iterations are reasonably fast: each iteration takes about 0.002 seconds on a good computer.\n",
    "\n",
    "These reasons lead us to use this instance of the `GeneticAlgorithm` class with larger images which would iterate more than a million times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Analysing Other Implemented Methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further justify the selection of the configurations in the previous section, we'll extend this analysis and compare how other methods fares for each step of the `GeneticAlgorithm` class. To avoid redefining the same setting every time we test a different method, the instance `GA` defined in the previous section will be copied and only the method we wish to compare it to will be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Tournament Selection**\n",
    "This alternative to the roulette method takes three more parameters than the roulette, making quite difficult to adjust these values. This is a method based on quality, so it is promising. The problem is that, since it is a comparison-based method, it is **slower** than the roulette method. Also, the improvements are also more gradual, almost converging very early. The roulette method beats this method in time, quality and simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mating = GA.define((tournament,[10,20,2,20])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mating = GA.define((roulette,[50])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Block Crossover**\n",
    "\n",
    "This method shows as much efficiency as the k-point crossover method. The noticeable difference is the gap between the fitness of the best to the worst individual: here the worst individual is significantly closer to the best individual, indicating a more hogeneous population. However, this observation does not suffice to label the block crossover as worse or better than the k-point. We can see small oscilations in the fittnes of the worst individual indicating a granular insertion of diversity. A more homegeneous population with a delicate insertion of diversity would likely lead to a better convergence rate on later generation which is considerably harder to improve the quality of the best individual. Since both methods appeared to as good as each other, we decided to go with a more classical (and slightly faster) approach: the k-point crossover method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.reprod = GA.define((block_crossover,[(20,20)])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.reprod = GA.define((k_point_crossover,[3])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Random Mutation**\n",
    "This method of mutation does not provides as much diversity as the reduced mutation as seem in the fitness graph below: the worst case individual is quite close regarding fitness when compared to the best. In later generations this reduced diversity might cause a halt in the convergence process. This method takes more time per iteration without a significant gain in convergence speed, which lead us to choose the reduced mutation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mutate = GA.define((random_mut,[0.05,0.025])) # Update method for the mutation step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mutate = GA.define((reduced_mut,[0.05,0.025])) # Update method for the mutation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Elitism Replacement**\n",
    "This method of replacement has a step convergence curve, at leas at first. Shortly after the intial fitness drop, we can see in the fitness curve the premature convergence of the population: the curve becomes almost a horizontal line. It's also noticeable how the diversity of the population is decimated, which contributes to the premature convergence. For these reasons, steady replacement presented itself as a more promising method of replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.replace = GA.define((elitism,None)) # Update method for the mutation step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.replace = GA.define((steady_state,None)) # Update method for the mutation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Parameter Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've selected some of the methods implemented, we can tweak the parameters of the selected methods to see if we can reach better results.\n",
    "\n",
    "Variations of the following parameters will be tested:\n",
    "* Population size for the random initilization method.\n",
    "* The amount of points in the k-point crossover method.\n",
    "* Number of couples generated by the roulette selection (defines amount of childs).\n",
    "* The Mutation Rate and Amount in reduced mutation.\n",
    "\n",
    "The `GA` class below uses the best parameters tested. It will be used as a reference for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA = GeneticAlgorithm(\n",
    "    limit     = 100000,\n",
    "    fit       = squared_error,\n",
    "    conv      = (convergence,(10000,)), \n",
    "    init      = (white_and_random,(100,)),\n",
    "    mating    = (roulette,[50]), \n",
    "    crossover = (k_point_crossover,[3]), \n",
    "    mutate    = (reduced_mut,[0.05,0.025]), # Has a good convergence after a long time\n",
    "    replace   = (steady_state,None), \n",
    "    )\n",
    "\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Population Size**\n",
    "\n",
    "Regardless if we are increasing or decreasing the population, the population becomes more homegeneous as indicated by the proximity between the worst and the best fit found. This behaviour is expected from a reduction in the population, however it's not what is expected of increasing it's size. Regarding convergence, the smaller population is faster while the larger is slower, as expected. There are no substantial differences in time per iteration. The value of 75 individuals appears to be the sweet spot for the method.\n",
    "\n",
    "Notice in the tests below that with 100 we obtain a lower fitness (1932927.0) than both with 50 and with 200 individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.init = GA.define((white_and_random,[50])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.init = GA.define((white_and_random,[100])) # Back to the original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.init = GA.define((random,[200])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.init = GA.define((random,[100])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Selected Couples**\n",
    "\n",
    "Selecting less couples presents a slower convergence rate, mostly beacause the amount of couples are directly related to the amount of childs generated. With less children there are less cadidates to optimize the best result found so far. Less children also implies less change, which justifies the similarity between the fitness of the worst and the best individuals found. Increasing the amount of couples can generate more childs, which improves the convergence rate as well as it kills diversity.\n",
    "The tested changes in the parameter also present a significant time change, it behaves almost linearly to the amount of couples, which is expected as the fitness calculation for the child of each couples is the most expensive step in the algorithm. \n",
    "The balance between these extremes was to generate a amount of $\\frac{50}{2}$ couples in a population of 100 individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mating = GA.define((roulette,[20])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mating = GA.define((roulette,[50])) # Back to the original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mating = GA.define((roulette,[70])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mating = GA.define((roulette,[50])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Crossover points**\n",
    "\n",
    " Increasing the amount of points creates an overhead in the iteration time to compute, as more copies of the genes must be made to complete the reproduction step, it also reduces the overall diversity of the population. For these reasons a small number of points was prefered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.reprod = GA.define((k_point_crossover,[5])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mating = GA.define((k_point_crossover,[3])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Mutation Parameters**\n",
    "\n",
    "Increasing either the mutation rate or the amount increases drastically the necessary time for each iteration. It also did not present any relevant improvements. The reduction of these values, despite improving performance to an extent, did not justify the loss of diversity, which can be particularly harmfull in later generations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mutate = GA.define((reduced_mut,[0.1,0.025])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mutate = GA.define((reduced_mut,[0.05,0.025])) # Back to the original method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GA.reset() # Creates a new instance using same methods and paramters\n",
    "GA.mutate = GA.define((reduced_mut,[0.05,0.05])) # Update method for the selection step\n",
    "GA.test('images/link.png', res_factor=0.6, graph=list(range(0, 100001, 5000)))\n",
    "GA.mutate = GA.define((reduced_mut,[0.05,0.025])) # Back to the original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Results and Analysis**\n",
    "\n",
    "After defining which settings works better for our purposes, we could apply the reconstruction algorithm in all images to do a more complete analysis of the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_points, all_times = [], []\n",
    "\n",
    "for name in img_names:\n",
    "    GA.reset() # Creates a new instance using same methods and parameters\n",
    "    GA.limit = GA.define(1000000) # Increase limit\n",
    "    GA.conv = GA.define((convergence, (50000,)))\n",
    "    GA.test('images/' + name, res_factor = 1, graph = list(range(0, 1000001, 50000)))\n",
    "    \n",
    "    # Store all fitness points and convergence times for quantitative analysis\n",
    "    all_imgs_points.append(GA.plot_points) \n",
    "    all_times.append(GA.convergence_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Qualitative Analysis**\n",
    "Overall, the best results achieved for the small images were of good quality and high similarity. In some cases, it was possible to considerably reduce the fitness value to quite low values. Some of the final results and their original versions can be seen below. With the big images, it was possible to achieve results that resemble the original, with a lot of noise. In the image 'objetos.png', for example, the noise filled most of the white space in the picture, even (but less so) when a white image is used as starting point.\n",
    "\n",
    "Two major problems that this project ran into were, in one hand, **premature convergence**, and on the other hand, **slow convergence speed**. Sometimes, both of these problems were present at once, when a lot of iterations were needed to keep optimizing the fitness value, and the convergence speed slowed down with still a high error value.\n",
    "\n",
    "As noted previously, the first problem was made better by adding exponential transfer to the roulette selection. While that made the small images converge a lot better, the larger images still ended up with slowdowns after a few hundreds of thousands of iterations. The image was still improving regularly, but not as fast as needed to achieve the desired result, since the error was still in the tens of millions. This leads to the second problem. The balancing act brought the project to its current state.\n",
    "\n",
    "A problem not related to convergence, however, is the slow iteration speed. This happens due to the amount of heavy operations in the code, such as the squared error and MSE calculations, and multiple instances of random number generation, be it with _NumPy_ arrays or regular lists. For these reasons, an iteration can be slow depending on the size of the input and the machine running the tests. The speed was improved with tweaks in different methods, avoiding repetition of calculations and using faster variations, but larger images still suffer with it. Since the larger images are also the ones that require more generations to converge, this becomes a big problem, which couldn't be solved so far, only improved.\n",
    "\n",
    "With a good computer or using the Google Colab environment, it takes a few hours to run 5 million iterations on the larger images, with resolution reduction factor of 0.6. Since this problem wasn't solved so far, the best course of action is to avoid it, using higher reduction factors or smaller images. This also validates the decision to use greyscale images instead of RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Image('Outputs/g2993857_link.png', width=150, height=150)\n",
    "y=Image('images/link.png', width=150, height=150)\n",
    "display(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Image('Outputs/g4000000_monalisa.png', width=150, height=150)\n",
    "y=Image('images/monalisa.png', width=150, height=150)\n",
    "display(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Image('Outputs/g271985_objetos_noisy.png', width=150, height=150)\n",
    "y=Image('images/objetos.png', width=150, height=150)\n",
    "display(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting case to discuss is `objetos.png`. It is the second largest image to be used in this project. After reduction, the resulting image has 142x142 px dimensions, and the original has 238x238 px. The main difference with the content of this image is the amount of white space it contains, and the fact that it consists of 9 separated objects instead of a continuous figure.\n",
    "\n",
    "The result above was obtained after 271985 generations, using the `random` initialization strategy. Notice how noisy the image is, in the white space and inside the objects. A noticeable characteristic is that the lighter objects are not as clear as the harder ones.\n",
    "\n",
    "It is clear that the amount of noise in the white space is hurting the fidelity of the result, and that would have to be cleared at some point. When, instead, we insert a white image in the original population, using the `white_and_random` function, the result is quite different. The result with a similar amount of generations can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('Outputs/g200000_objetos.png', width=150, height=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That image, while still noisy, is much more clear than the one before, because the white image already starts with a lot of correct pixels. The noise is a result of collateral damage by mutation and over-crossover: the result is still a net positive from the full white. \n",
    "\n",
    "But a problem that might arise from this case is the homogenization of a part of the image. If every individual comes from the white board, it is possible that every image has the bottom half as just white, especially using the `elitism` replacement method, since crossovers in the upper half are more valuable than the bottom half in terms of optimization.\n",
    "\n",
    "We can see that, while most noise is in the upper half, there are some shades of grey in the bottom half as well, so this could be due to the multi-point crossover and steady state replacement method. In this case, the introduction of the white image made a big difference in convergence speed, and that is true for all images with a white background in this GA configuration. The best result for this image is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('Outputs/g5000000_objetos.png', width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Quantitative Analysis**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data stored when all tests run, it's possible to build a table that displays the images fitness and convergence speeds side by side, providing a wider visualization of the results obtained. To do a more fair comparision, we divide in the table each image fitness by it's dimensions (height $\\times$ width), as the squared error per se does'nt work too well as a comparision metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Define data for each image\n",
    "for i, name in enumerate(img_names):\n",
    "    \n",
    "    h, w = images[i].shape\n",
    "    dim = h*w\n",
    "    dim_str = '(' + str(h) + 'x' + str(w) + ')'\n",
    "    \n",
    "    # Detach points from tuples \n",
    "    data[name + ' best fitness / ' + dim_str] = [x[0] / dim for x in all_imgs_points[i]]\n",
    "    data[name + ' median fitness / ' + dim_str] = [x[1] / dim for x in all_imgs_points[i]]\n",
    "    data[name + ' worst fitness / ' + dim_str] = [x[2] / dim for x in all_imgs_points[i]]\n",
    "    data[name + ' convergence time(s)'] = all_times[i]\n",
    "\n",
    "# Increase max size\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Convert dict into DataFrame, indexed by generations\n",
    "index = ['gen ' + str(x) for x in GA.plot_milestones[1:]] # Discard 0\n",
    "df = pd.DataFrame(data, columns = data, index = index)\n",
    "\n",
    "# Image separators\n",
    "def css_border(x,pos):\n",
    "    return [\"border-left: 1px solid black\" if i in pos else \"border: 0px\" for i, col in enumerate(x)]\n",
    "def display_df_with_delimiter(df,pos):\n",
    "    return df.style.apply(partial(css_border,pos=pos), axis=1)\n",
    "\n",
    "# Display table\n",
    "display_df_with_delimiter(df, [x for x in range(len(data))[::4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indeed reinforces what was observed and previously analyzed: not only were the last generations fitness values quite low (and therefore good) for smaller images, but they were obtained considerably faster. This is not a surprise, as we are applying the same method over individuals that grows exponentially in terms of possible gene configurations. Even so, the algorithm kept converging at a reasonable rate until the end, even for larger images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusions**\n",
    "\n",
    "### General Conclusions\n",
    "As expected, the amount of possibilities makes this a hard problem to solve, especially for higher resolution images. The initial error values can be astronomical, and the optimization can be slow, even if regular.\n",
    "\n",
    "Still, the results achieved with small images are really similar to the original, even in full resolution, so this project was a success in that front. With really small images, the a very similar result could be achieved in just a few thousand generations. Most of those images, though, reached minimum point after which there was no improvement found, even after hundreds of thousands of generations.\n",
    "\n",
    "This, along with the noisy result that the larger images returned, lead to the conclusion that the GA is not exactly copying the goal image, but getting \"close enough\" so that the characteristics of the original image are present, but not clear of noise or sometimes even whole. This inability of removing noise or getting an exact copy of the original image can be seen as a characteristic of GA, with random movements, crossover and mutation. \n",
    "\n",
    "To achieve an exact copy of the image, one individual has to at some point go through a perfect crossover+mutation process, where the last different pixel becomes the exact same shade as the original image and no other pixels are changed. Since the method is random, the chances of that happening are very slim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "Future work for this project would be to speed up each iteration so that larger images can be tested in appropriate times, and test different or more exotic methods of reproduction, mutation and others. In this project, the mutation rate (MR) was **static**, so a dynamic MR could lead to different results as well. This project can also be scaled to deal with colored images, especially if the aforementioned problems are solved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('mc906': virtualenv)",
   "language": "python",
   "name": "python36964bitmc906virtualenv7dec5718c7b3422688b8879a7762f26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
