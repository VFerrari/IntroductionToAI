{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import timeit\n",
    "import numpy as np\n",
    "from search import astar_search, manhattan_distance\n",
    "from mazes import gen_sparses, get_mazes\n",
    "from PacProblem import PacProblem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases\n",
    "\n",
    "For testing purposes, we generated 10 mazes using the [tool provided by classmate Gabriel Bomfim](https://gabomfim.github.io/pacman-mazegen/tetris/many.htm) in Google Classrom, which adapts the [maze generator](https://shaunlebron.github.io/pacman-mazegen/) linked in the project description. Each tile is represented by a char, where **|** and **-** are walls, **.** are foods and **o** are ghosts. We put the start and goal position in all mazes, respectively symbolized by **!** and **?**.\n",
    "\n",
    "As this tool creates mazes fully filled with food, we thought that it would be good for comparision to also test sparse mazes, which we created by randomly removing dots in the dense ones. The variations, together with the originals, are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denses, sparses = get_mazes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* Search Solution\n",
    "\n",
    "As an informed search algorithm, A\\* takes into account information about the path cost together with an heuristic to evaluate which is the most promising path to take when it enters a state. For this evaluation, A\\* chooses in state $n$ to proceed to the neighbor that gives the lowest $f(n) = g(n) + h(n)$, $g(n)$ being the exact path cost from starting state to $n$ and $h(n)$ the heuristic estimated cost from $n$ to goal state.\n",
    "\n",
    "### Heuristic\n",
    "\n",
    "How fast the agent reaches the goal in A\\* depends highly on the heuristic implemented and how it affects the nodes expansion. In a problem like ours, where the maze configuration needs to be known in state $n$ so $f(n)$ can be calculated, it's specially important to pick a good heuristic - after all, the search space is exponentially large, as each subset of eaten food represents a different node, even with the agent in a fixed position.\n",
    "\n",
    "A common approach to simpler pathfinding problems is to use the **Manhattan distance** as a heuristic, which is the distance between the agent and the goal positions measured along axes at right angles (i.e., $|x_1 - x_2| + |y_1 - y_2|$, given that the agent is in $(x_1, y_1)$ and the goal is to reach $(x_2, y_2)$). In our problem, however, is not realistic to estimate a good cost to goal using this distance, as the foods over the maze can make it very far from optimal.\n",
    "\n",
    "Considering that, we implement the sum of Manhattan distances between the agent and all the foods as a heuristic, as it's highly possible that they will all be eaten in the optimal path. Notice that this sum can overestimate the optimal, because it's not always true that all the foods will be eaten in the best path. As a overestimating heuristic, it breaks admissibility - that is, A\\* is not guaranteed to find the optimal path. Even so, as our problem gives a high score to Pac-Man when it eats, we chose it expecting A\\* will find good, if not optimal, paths in reasonable running times. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_heuristic(node):\n",
    "    ''' sum of manhattan distances between Pac-Man and all foods in maze '''\n",
    "    \n",
    "    # Detach maze configuration and Pac-Man position\n",
    "    tuple_maze, idx = node.state\n",
    "    \n",
    "    # Accumulate sum of manhattan distances to foods\n",
    "    md_sum = 0\n",
    "    for food_idx in np.argwhere(maze == '.'):\n",
    "        md_sum += manhattan_distance(food_idx, idx)\n",
    "            \n",
    "    return md_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP (Testing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Script to run all tests and identify start + goal\n",
    "# automatically\n",
    "\n",
    "# Big maze 2\n",
    "maze = []\n",
    "for line in open('./mazes/big/2', 'r').readlines():\n",
    "    # Remove trailing new lines\n",
    "    row = list(line.rstrip('\\n'))\n",
    "    \n",
    "    # Erase ! and ? chars\n",
    "    row = [' ' if (c == '!' or c == '?') else c for c in row]\n",
    "    \n",
    "    maze.append(row)\n",
    "\n",
    "# Maze as a tuple of tuples\n",
    "maze = tuple(map(tuple, maze))\n",
    "print('\\n'.join(map(str, maze)))\n",
    "\n",
    "start = (1, 1) # ! in file\n",
    "goal = (1, 15) # ? in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Problem with maze in state\n",
    "problem = PacProblem((maze, start), goal)\n",
    "sol = astar_search(problem, astar_heuristic)\n",
    "\n",
    "print('Actions: ', sol.solution())\n",
    "print('Score: ', -1*sol.path_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapting heuristic for testing with no maze;\n",
    "# probably there is a better way to do this\n",
    "from SearchAgent import SearchAgent\n",
    "from PacProblemNoMaze import PacProblem\n",
    "\n",
    "def h(node):\n",
    "    ''' sum of manhattan distances between Pac-Man and all foods in maze '''\n",
    "\n",
    "    # Detach maze configuration and Pac-Man position\n",
    "    idx = node.state\n",
    "    \n",
    "    # Accumulate sum of manhattan distances to foods\n",
    "    md_sum = 0\n",
    "    for food_idx in np.argwhere(maze == '.'):\n",
    "        md_sum += manhattan_distance(food_idx, idx)\n",
    "            \n",
    "    return md_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Problem without maze in state\n",
    "maze = np.array(maze).astype('bytes')\n",
    "problem = PacProblem(start, goal, maze)\n",
    "sol = astar_search(problem, h)\n",
    "\n",
    "print('Actions: ', sol.solution())\n",
    "print('Score: ', -1*sol.path_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('mc906': virtualenv)",
   "language": "python",
   "name": "python36964bitmc906virtualenv7dec5718c7b3422688b8879a7762f26b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
